{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "coefficients = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created training dataset. Sample from training data: {u'is_root': False, u'text': u'ITS RAINING SIDEWAYS', u'popularity_score': 1.254698160267241, u'controversiality': 0, u'children': 0}\n",
      "Created validation dataset. Sample from validation data: {u'is_root': True, u'text': u'Kidney infection and subsequent stones. ', u'popularity_score': 0.8433369681773519, u'controversiality': 0, u'children': 0}\n",
      "Created test dataset. Sample from validation data: {u'is_root': True, u'text': u\"Some asshole shot 9 innocent people at a church.  I live in such a beautiful city, and it sucks that this made national headlines.  Charleston is beautiful.  It's been proven over and over again.  You owe it to yourself to visit.\", u'popularity_score': 0.7204745721237265, u'controversiality': 0, u'children': 1}\n",
      "Finding top words\n"
     ]
    }
   ],
   "source": [
    "# %run data_processing.py\n",
    "import numpy as np\n",
    "import json\n",
    "import string\n",
    "import operator\n",
    "from collections import *\n",
    "\n",
    "class OrderedCounter(Counter, OrderedDict):\n",
    "    pass\n",
    "\n",
    "# array is \n",
    "\n",
    "\n",
    "\"\"\"\n",
    " Brainstormed features:\n",
    " - sentiment analysis\n",
    "\"\"\"\n",
    "\n",
    "def add_features(top_words, data):\n",
    "    # Word count feature\n",
    "    # 100 data points\n",
    "    x_train = np.zeros((10000, 161))\n",
    "    y_train = np.zeros(10000)\n",
    "    i = 0\n",
    "    for data_point in data:\n",
    "        features = np.zeros(161)\n",
    "        word_list = process_string(data_point['text'])\n",
    "    \n",
    "        for word in word_list:\n",
    "            if word in top_words:\n",
    "                index = top_words.index(word)\n",
    "                features[index] += 1\n",
    "        features[160] = 1\n",
    "        x_train[i] = features\n",
    "        y_train[i] = data_point[\"popularity_score\"]\n",
    "        i = i+1\n",
    "\n",
    "    # TODO: at least two more features: these can be \n",
    "    # based on the text data, transformations of the other numeric features, or interaction terms. \n",
    "    return x_train, y_train\n",
    "\n",
    "def calculate_closed_form(X, Y):\n",
    "    coeffs = np.linalg.inv(X.transpose().dot(X)).dot(X.transpose()).dot(Y)\n",
    "    return coeffs\n",
    "\n",
    "def read_json_file():\n",
    "    file = open('./data/proj1_data.json', 'r')\n",
    "    data= file.read()\n",
    "    file.close()\n",
    "    json_data = json.loads(data)\n",
    "    return json_data\n",
    "\n",
    "def process_string(str):\n",
    "    return str.lower().split(' ')\n",
    "\n",
    "def count_top_words(data):\n",
    "    print(\"Finding top words\")\n",
    "    word_freq = OrderedCounter()\n",
    "    for line in data:\n",
    "        word_list = process_string(line['text'])\n",
    "        word_freq.update(word_list)\n",
    "    most_common = dict(word_freq.most_common(160))\n",
    "    return list(most_common.keys())\n",
    "\n",
    "def split_data(data, first_split, second_split, third_split):\n",
    "    train, validation, test = [], [], []\n",
    "\n",
    "    for i in range(0, first_split):\n",
    "        train.append(data[i])\n",
    "    print((\"Created training dataset. Sample from training data: {}\").format(train[0]))\n",
    "\n",
    "    for i in range(first_split, second_split):\n",
    "        validation.append(data[i])\n",
    "    print((\"Created validation dataset. Sample from validation data: {}\").format(validation[0]))\n",
    "\n",
    "    for i in range(second_split, third_split):\n",
    "        test.append(data[i]) \n",
    "    print((\"Created test dataset. Sample from validation data: {}\").format(test[0]))\n",
    "\n",
    "    return train, validation, test\n",
    "\n",
    "def main():\n",
    "    data = read_json_file()\n",
    "\n",
    "    \"\"\"\n",
    "    Use the first 10,000 points for training, the next 1,000 for validation, and the final 1,000 for testing.\n",
    "    \"\"\"\n",
    "    train, validation, test = split_data(data, 10000, 11000, 12000)\n",
    "\n",
    "    top_words = count_top_words(train)\n",
    "    # print(top_words)\n",
    "    \n",
    "    data_with_features, y_train = add_features(top_words, train)\n",
    "    coefficients = calculate_closed_form(data_with_features, y_train)\n",
    "    return coefficients\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    coefficients = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error is 1.046832911778383 for closed form weights on the training set.\n",
      "Mean squared error is 1.047460429101807 for gradient descent weights on the training set.\n",
      "Mean squared error is 0.9895357003238052 for closed form weights on the validation set.\n",
      "Mean squared error is 0.9905534926478462 for gradient descent weights on the validation set.\n",
      "MSE is 1.084683070915726 for no-text features model on the training set. (closed form)\n",
      "MSE is 1.0203266848431438 for no-text features model on the validation set. (closed form)\n",
      "MSE is 1.0602298261175074 for 60-word features model on the training set. (closed form)\n",
      "MSE is 0.9831859696254964 for 60-word features model on the validation set. (closed form)\n",
      "MSE is 1.046832911778383 for 160-word features model on the training set. (closed form)\n",
      "MSE is 0.9895357003238052 for 160-word features model on the validation set. (closed form)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import string\n",
    "import operator\n",
    "from collections import *\n",
    "\n",
    "class OrderedCounter(Counter, OrderedDict):\n",
    "    pass\n",
    "\n",
    "\"\"\"\n",
    " Brainstormed features:\n",
    " - sentiment analysis\n",
    "\"\"\"\n",
    "\n",
    "def get_features(top_words, data):\n",
    "    num_data_points = len(data)\n",
    "    num_features = len(top_words) + 4\n",
    "\n",
    "    x_train = np.zeros((num_data_points, num_features))\n",
    "    y_train = np.zeros(num_data_points)\n",
    "    i = 0\n",
    "    for data_point in data:\n",
    "        features = np.zeros(num_features)\n",
    "        word_list = process_string(data_point['text'])\n",
    "    \n",
    "        for word in word_list:\n",
    "            if word in top_words:\n",
    "                index = top_words.index(word)\n",
    "                features[index] += 1\n",
    "\n",
    "        features[num_features - 4] = data_point[\"controversiality\"]\n",
    "        features[num_features - 3] = data_point[\"children\"]\n",
    "        features[num_features - 2] = 1 if data_point[\"is_root\"] else 0\n",
    "        features[num_features - 1] = 1 # bias term\n",
    "\n",
    "        x_train[i] = features\n",
    "        y_train[i] = data_point[\"popularity_score\"]\n",
    "        i = i+1\n",
    "\n",
    "    # TODO: at least two more features: these can be \n",
    "    # based on the text data, transformations of the other numeric features, or interaction terms. \n",
    "    return x_train, y_train\n",
    "\n",
    "def calculate_closed_form(X, Y):\n",
    "    coeffs = np.linalg.inv(X.transpose().dot(X)).dot(X.transpose()).dot(Y)\n",
    "    return coeffs\n",
    "\n",
    "def calculate_gradient_descent(X, y, init_weights, beta=10**-9, alpha=10**-6, epsilon=4*10**-5):\n",
    "    error = 10\n",
    "    new_weights = init_weights\n",
    "\n",
    "    while error > epsilon:\n",
    "        weights = new_weights\n",
    "\n",
    "        # the error was here, Prof mentioned in class that the learning rate\n",
    "        # should be scaled by 1/n where n = # training points\n",
    "        gradient = X.T.dot(X.dot(weights) - y)\n",
    "        new_weights = weights - 2* alpha/(1+beta) * gradient\n",
    "        error = np.linalg.norm((new_weights - weights),2)\n",
    "        # print(error)\n",
    "\n",
    "    return new_weights\n",
    "\n",
    "def read_json_file():\n",
    "    file = open('./data/proj1_data.json', 'r')\n",
    "    data= file.read()\n",
    "    file.close()\n",
    "    json_data = json.loads(data)\n",
    "    return json_data\n",
    "\n",
    "def process_string(str):\n",
    "    return str.lower().split(' ')\n",
    "\n",
    "def count_top_words(data, num_top_words):\n",
    "    word_freq = OrderedCounter()\n",
    "    for line in data:\n",
    "        word_list = process_string(line['text'])\n",
    "        word_freq.update(word_list)\n",
    "    most_common = dict(word_freq.most_common(num_top_words))\n",
    "    return list(most_common.keys())\n",
    "\n",
    "def split_data(data, first_split, second_split, third_split):\n",
    "    train, validation, test = [], [], []\n",
    "\n",
    "    for i in range(0, first_split):\n",
    "        train.append(data[i])\n",
    "\n",
    "    for i in range(first_split, second_split):\n",
    "        validation.append(data[i])\n",
    "\n",
    "    for i in range(second_split, third_split):\n",
    "        test.append(data[i]) \n",
    "\n",
    "    return train, validation, test\n",
    "\n",
    "def calculate_mean_squared_error(predicted_scores, actual_scores):\n",
    "    total_error = 0\n",
    "    for x, y in np.nditer([predicted_scores, actual_scores]):\n",
    "        squared_difference = (x - y)**2 \n",
    "        total_error += squared_difference\n",
    "    mean_squared_error = total_error / len(predicted_scores)\n",
    "    return mean_squared_error\n",
    "\n",
    "def evaluate_model(top_words, weights, dataset):\n",
    "    x_validate, y_validate = get_features(top_words, dataset)\n",
    "    predicted_scores_validate = x_validate.dot(weights)\n",
    "    actual_scores_validate = y_validate\n",
    "    error = calculate_mean_squared_error(predicted_scores_validate, actual_scores_validate)\n",
    "    return error \n",
    "\n",
    "def main():\n",
    "    data = read_json_file()\n",
    "\n",
    "    \"\"\"\n",
    "    Use the first 10,000 points for training, the next 1,000 for validation, and the final 1,000 for testing.\n",
    "    \"\"\"\n",
    "    train, validation, test = split_data(data, 10000, 11000, 12000)\n",
    "\n",
    "    top_words = count_top_words(train, 160) # top 160 words\n",
    "    \n",
    "    x_train, y_train = get_features(top_words, train)\n",
    "\n",
    "    \"\"\"\n",
    "    Calculate closed form and gradient descent weights.\n",
    "    \"\"\"\n",
    "    closed_form_weights = calculate_closed_form(x_train, y_train)\n",
    "    closed_form_error = evaluate_model(top_words, closed_form_weights, train)\n",
    "    print(\"Mean squared error is \" + str(closed_form_error) + \" for closed form weights on the training set.\")\n",
    "\n",
    "    weights = np.zeros(164)\n",
    "    gradient_descent_weights = calculate_gradient_descent(x_train, y_train, weights, beta=0.1)\n",
    "    gradient_descent_error = evaluate_model(top_words, gradient_descent_weights, train)\n",
    "    print(\"Mean squared error is \" + str(gradient_descent_error) + \" for gradient descent weights on the training set.\")\n",
    " \n",
    "    # print out weights, include in report\n",
    "    \"\"\"\n",
    "    Evaluate closed form and gradient descent weights.\n",
    "    \"\"\"\n",
    "    closed_form_error = evaluate_model(top_words, closed_form_weights, validation)\n",
    "    print(\"Mean squared error is \" + str(closed_form_error) + \" for closed form weights on the validation set.\")\n",
    "\n",
    "    gradient_descent_error = evaluate_model(top_words, gradient_descent_weights, validation)\n",
    "    print(\"Mean squared error is \" + str(gradient_descent_error) + \" for gradient descent weights on the validation set.\")\n",
    "\n",
    "    \"\"\"\n",
    "    Create and evaluate models with no text features, top 60 words, and top 160 words\n",
    "    \"\"\"\n",
    "    # no text features\n",
    "    no_text_x_train, no_text_y_train = get_features([], train)\n",
    "    no_text_closed_form_weights = calculate_closed_form(no_text_x_train, no_text_y_train)\n",
    "    no_text_training_error = evaluate_model([], no_text_closed_form_weights, train)\n",
    "    no_text_validation_error = evaluate_model([], no_text_closed_form_weights, validation)\n",
    "    print(\"MSE is \" + str(no_text_training_error) + \" for no-text features model on the training set. (closed form)\" )\n",
    "    print(\"MSE is \" + str(no_text_validation_error) + \" for no-text features model on the validation set. (closed form)\" )\n",
    "\n",
    "    # top 60 words\n",
    "    top_words = count_top_words(train, 60)\n",
    "    top60_x_train, top60_y_train = get_features(top_words, train)\n",
    "    top60_closed_form_weights = calculate_closed_form(top60_x_train, top60_y_train)\n",
    "    top60_training_error = evaluate_model(top_words, top60_closed_form_weights, train)\n",
    "    top60_validation_error = evaluate_model(top_words, top60_closed_form_weights, validation)\n",
    "    print(\"MSE is \" + str(top60_training_error) + \" for 60-word features model on the training set. (closed form)\" )\n",
    "    print(\"MSE is \" + str(top60_validation_error) + \" for 60-word features model on the validation set. (closed form)\" )\n",
    "\n",
    "    # top 160 words\n",
    "    top_words = count_top_words(train, 160)\n",
    "    top160_x_train, top60_y_train = get_features(top_words, train)\n",
    "    top160_closed_form_weights = calculate_closed_form(top160_x_train, top60_y_train)\n",
    "    top160_training_error = evaluate_model(top_words, top160_closed_form_weights, train)\n",
    "    top160_validation_error = evaluate_model(top_words, top160_closed_form_weights, validation)\n",
    "    print(\"MSE is \" + str(top160_training_error) + \" for 160-word features model on the training set. (closed form)\" )\n",
    "    print(\"MSE is \" + str(top160_validation_error) + \" for 160-word features model on the validation set. (closed form)\" )\n",
    "\n",
    "    return top160_closed_form_weights\n",
    "\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    coefficients = main()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.57326527e-02, -2.66172151e-02, -3.16713926e-02, -1.53615707e-02,\n",
       "       -1.69212094e-02,  1.10177497e-01, -6.87424078e-02, -3.45790377e-01,\n",
       "       -8.07603150e-03,  1.53664035e-01,  1.46223824e-03, -1.05436342e-01,\n",
       "       -2.29243172e-02, -2.77632929e-02,  3.62832200e-02, -4.18932753e-02,\n",
       "        3.66383322e-02,  5.57573422e-02, -2.00102377e-02,  1.23010851e-02,\n",
       "        1.57306918e-01, -9.21680830e-02,  1.72372225e-02, -7.88188991e-02,\n",
       "       -3.07127647e-02,  2.80994583e-03,  5.01890214e-02,  8.50286847e-02,\n",
       "        1.04709616e-01,  4.65085186e-02,  9.77255587e-03,  2.76666344e-02,\n",
       "        4.02936648e-02, -3.24480078e-03,  1.83087857e-02,  9.81627956e-03,\n",
       "       -1.50235710e-02, -2.06605618e-02,  2.25162577e-02,  3.46953854e-02,\n",
       "        4.60630807e-02,  6.28455535e-02,  9.95447999e-04,  7.58977519e-03,\n",
       "        1.65528023e-01, -1.54850903e-03,  6.50730793e-03,  5.70486300e-02,\n",
       "        9.45517249e-03, -4.19840305e-03,  4.88163293e-03, -6.55747889e-03,\n",
       "       -6.87433904e-02,  2.84004559e-02,  3.14683630e-02, -2.31938763e-01,\n",
       "        2.67311805e-01,  2.45789396e-02,  4.01163159e-02, -4.07852003e-02,\n",
       "        2.85868787e-02,  3.38020485e-03,  3.40472766e-02, -1.24747477e-01,\n",
       "       -1.19771519e-01,  8.66838738e-02, -1.03200503e-01, -2.71168280e-02,\n",
       "        4.03619129e-02, -2.96861638e-03,  5.69405408e-02, -2.71381655e-03,\n",
       "        2.28478915e-02,  5.46425634e-02, -3.28253945e-01,  2.59087188e-01,\n",
       "       -9.44430624e-02,  2.77128211e-02,  3.51555890e-02,  4.30180371e-02,\n",
       "        1.22150746e-01,  1.49533871e-01, -2.06266838e-02,  1.74115617e-02,\n",
       "       -1.00487852e-01,  7.42303734e-02, -3.03388561e-01, -2.49856449e-02,\n",
       "        5.32556115e-02,  6.40133414e-02, -6.55907447e-02, -8.51220143e-02,\n",
       "       -3.07726989e-02,  3.86033567e-03, -4.99713539e-02, -1.74422408e-03,\n",
       "        7.63121512e-02, -4.26986384e-02,  5.48816405e-02,  1.38917336e-02,\n",
       "        6.09043891e-02, -1.52917406e-01,  6.58190062e-02,  5.16760942e-02,\n",
       "       -2.50408273e-03, -4.95535631e-02,  1.46433419e-02,  6.59383307e-02,\n",
       "       -1.75650585e-02, -2.20694641e-02,  4.17187459e-02,  3.01516931e-02,\n",
       "       -5.69023686e-02,  5.04728378e-02, -1.52160403e-02, -4.09597861e-02,\n",
       "       -5.60878090e-02, -2.53716928e-02,  4.95263386e-02,  1.24804962e-01,\n",
       "        9.11490591e-03,  1.40106801e-02, -1.02720208e-02,  5.61781655e-04,\n",
       "       -4.68513989e-02,  2.41729598e-03,  1.66511277e-02, -2.68399612e-02,\n",
       "       -2.41110516e-02,  1.39061789e-01,  2.57372113e-02, -5.26062971e-02,\n",
       "        2.79949886e-02, -3.36489716e-02,  5.59828709e-03, -1.66578275e-02,\n",
       "       -6.58579351e-02, -5.89533460e-02,  5.57769478e-02,  8.68107246e-02,\n",
       "        3.63649203e-02, -1.11581104e-03, -3.88773064e-02, -2.55193722e-02,\n",
       "       -1.32039674e-01, -1.34177150e-01, -6.09311510e-02, -3.28856510e-02,\n",
       "        3.33025581e-02,  1.72770168e-02, -4.04085482e-02, -6.94227799e-02,\n",
       "       -1.58124506e-02,  2.12955256e-02, -2.17959434e-02, -2.95122893e-02,\n",
       "        3.09007613e-02, -9.19326791e-02, -9.67681035e-03, -6.02087960e-02,\n",
       "       -1.06660606e+00,  3.73565864e-01, -2.37344613e-01,  8.51770262e-01])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dict = {\"Controversiality\": -1.06660606e+00, \"Children\": 3.73565864e-01, \"Is_root\": -2.37344613e-01, \"Bias term\": 8.51770262e-01 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Weights for non-text features')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=feature_dict.keys(), y=feature_dict.values(), palette=\"pastel\").set_title(\"Weights for non-text features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
